{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train U-Net for cervix/os detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Run on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GT 750M (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2 \n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Project\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'common')))\n",
    "from data_utils import type_1_ids, type_2_ids, type_3_ids, test_ids\n",
    "from data_utils import RESOURCES_PATH, GENERATED_DATA, get_annotations\n",
    "from training_utils import get_trainval_id_type_lists2, get_test_id_type_list2\n",
    "from image_utils import get_image_data\n",
    "from metrics import logloss_mc\n",
    "from unet_keras_v1 import get_unet\n",
    "\n",
    "# Local keras-contrib:\n",
    "from preprocessing.image.generators import ImageMaskGenerator\n",
    "from preprocessing.image.iterators import XYIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2017)\n",
    "\n",
    "def xy_provider(image_id_type_list, \n",
    "                image_size=(224, 224), \n",
    "                test_mode=False,\n",
    "                verbose=0):        \n",
    "    while True:\n",
    "        for i, (image_id, image_type) in enumerate(image_id_type_list):\n",
    "            if verbose > 0:\n",
    "                print(\"Image id/type:\", image_id, image_type, \"| counter=\", counter)\n",
    "\n",
    "            img = get_image_data(image_id, image_type)\n",
    "            if img.dtype.kind is not 'u':\n",
    "                if verbose > 0:\n",
    "                    print(\"Image is corrupted. Id/Type:\", image_id, image_type)\n",
    "                continue\n",
    "            img = cv2.resize(img, dsize=image_size[::-1])\n",
    "            img = img.transpose([2, 0, 1])\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "\n",
    "            label = get_image_data(image_id + \"_\" + image_type, \"label\")\n",
    "            label = cv2.resize(label, dsize=image_size[::-1])\n",
    "            label = label.transpose([2, 0, 1])\n",
    "\n",
    "            if test_mode:\n",
    "                yield img, label, (image_id, image_type)\n",
    "            else:\n",
    "                yield img, label\n",
    "                \n",
    "        if test_mode:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_id_type_list, val_id_type_list, batch_size=16, nb_epochs=10, image_size=(224, 224)):\n",
    "    \n",
    "    samples_per_epoch = (1024 // batch_size) * batch_size\n",
    "    nb_val_samples = (256 // batch_size) * batch_size\n",
    "    #samples_per_epoch = (2048 // batch_size) * batch_size\n",
    "    #nb_val_samples = (1024 // batch_size) * batch_size\n",
    "\n",
    "    if not os.path.exists('weights'):\n",
    "        os.mkdir('weights')\n",
    "\n",
    "    weights_filename = os.path.join(\"weights\", \"unet_os_cervix_detector_{epoch:02d}-{val_loss:.4f}.h5\")\n",
    "    model_checkpoint = ModelCheckpoint(weights_filename, monitor='loss', save_best_only=True)\n",
    "\n",
    "    print(\"Training parameters: \", batch_size, nb_epochs, samples_per_epoch, nb_val_samples)\n",
    "    \n",
    "    train_gen = ImageMaskGenerator(featurewise_center=True,\n",
    "                                   featurewise_std_normalization=True,\n",
    "                                   rotation_range=90., \n",
    "                                   width_shift_range=0.15, height_shift_range=0.15,\n",
    "                                   shear_range=3.14/6.0,\n",
    "                                   zoom_range=0.25,\n",
    "                                   channel_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "    val_gen = ImageMaskGenerator(rotation_range=90., \n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True)\n",
    "    \n",
    "    train_gen.fit(xy_provider(train_id_type_list, test_mode=True),\n",
    "                  len(train_id_type_list), \n",
    "                  augment=True, \n",
    "                  save_to_dir=GENERATED_DATA,\n",
    "                  save_prefix='os_cervix',\n",
    "                  batch_size=4,\n",
    "                  verbose=1)\n",
    "   \n",
    "    history = model.fit_generator(\n",
    "        train_gen.flow(xy_provider(train_id_type_list), \n",
    "                       len(train_id_type_list),\n",
    "                       batch_size=batch_size),\n",
    "        samples_per_epoch=samples_per_epoch,\n",
    "        nb_epoch=nb_epochs,\n",
    "        validation_data=val_gen.flow(xy_provider(val_id_type_list), \n",
    "                       len(val_id_type_list),\n",
    "                       batch_size=batch_size),\n",
    "        nb_val_samples=nb_val_samples,\n",
    "        callbacks=[model_checkpoint],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, val_id_type_list, batch_size=16, image_size=(224, 224)):\n",
    "      \n",
    "    val_iter = XYIterator(xy_provider(val_id_type_list, test_mode=True), \n",
    "                          len(val_id_type_list), \n",
    "                          None, # image generator\n",
    "                          batch_size=batch_size,\n",
    "                          data_format='channels_first')\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_counter = 0 \n",
    "    for x, y_true, info in val_iter:           \n",
    "        s = y_true.shape[0]\n",
    "        total_counter += s\n",
    "        y_pred = model.predict(x)\n",
    "        loss = logloss_mc(y_true, y_pred)\n",
    "        total_loss += s * loss\n",
    "        print(\"--\", total_counter, \"batch loss : \", loss)\n",
    "\n",
    "    if total_counter == 0:\n",
    "        total_counter += 1\n",
    "\n",
    "    total_loss *= 1.0 / total_counter   \n",
    "    print(\"Total loss : \", total_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, test_id_type_list, batch_size=16, image_size=(224, 224), info=''):\n",
    "\n",
    "    \n",
    "    test_iter = XYIterator(xy_provider(val_id_type_list, test_mode=True), \n",
    "                          len(val_id_type_list), \n",
    "                          None, # image generator\n",
    "                          batch_size=batch_size,\n",
    "                          data_format='channels_first')\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(columns=['image_name', 'image_type', 'os', 'cervix'])\n",
    "    total_counter = 0\n",
    "    for x, _, info image_ids in test_iter:            \n",
    "        y_pred = model.predict(y)    \n",
    "        s = X.shape[0]\n",
    "        total_counter += s\n",
    "        print(\"--\", total_counter)\n",
    "        for i in range(s):\n",
    "            df.loc[total_counter + i, :] = (image_ids[i] + '.jpg', ) + tuple(Y_pred[i, :])\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    df.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2017-03-28 22:39:13.798069 - Get train/val lists ...\n",
      "Total : 208, Train : 156, Val : 52\n",
      "\n",
      " 2017-03-28 22:39:13.809415 - Get U-Net model ...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n {} - Get train/val lists ...\".format(datetime.datetime.now()))        \n",
    "sloth_annotations_filename = os.path.join(RESOURCES_PATH, 'cervix_os.json')\n",
    "annotations = get_annotations(sloth_annotations_filename)\n",
    "\n",
    "train_id_type_list, val_id_type_list = get_trainval_id_type_lists2(annotations=annotations, val_split=0.25)\n",
    "\n",
    "print \"Total : %s, Train : %s, Val : %s\" % (len(annotations), len(train_id_type_list), len(val_id_type_list))\n",
    "\n",
    "print(\"\\n {} - Get U-Net model ...\".format(datetime.datetime.now()))\n",
    "unet = get_unet(input_shape=(3, 224, 224), n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 224, 224)  896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 32, 224, 224)  128         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 224, 224)  0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 224, 224)  9248        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 32, 224, 224)  128         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 224, 224)  0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 112, 112)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 112, 112)  18496       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 64, 112, 112)  256         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 64, 112, 112)  0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 112, 112)  36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 64, 112, 112)  256         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 64, 112, 112)  0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 56, 56)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 128, 56, 56)   73856       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 128, 56, 56)   512         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128, 56, 56)   0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 128, 56, 56)   147584      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 128, 56, 56)   512         convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 128, 56, 56)   0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 128, 28, 28)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 28, 28)   295168      maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 256, 28, 28)   1024        convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 256, 28, 28)   0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 256, 28, 28)   590080      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 256, 28, 28)   1024        convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 256, 28, 28)   0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 256, 14, 14)   0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 14, 14)   1180160     maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 512, 14, 14)   2048        convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 512, 14, 14)   0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 14, 14)   2359808     activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 512, 14, 14)   2048        convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 512, 14, 14)   0           batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 1024, 7, 7)    4719616     maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 1024, 7, 7)    4096        convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 1024, 7, 7)    0           batchnormalization_11[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 1024, 7, 7)    9438208     activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 1024, 7, 7)    4096        convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 1024, 7, 7)    0           batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_1 (UpSampling2D)    (None, 1024, 14, 14)  0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 1536, 14, 14)  0           upsampling2d_1[0][0]             \n",
      "                                                                   activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   7078400     merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNorm (None, 512, 14, 14)   2048        convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 512, 14, 14)   0           batchnormalization_13[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 512, 14, 14)   2359808     activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorm (None, 512, 14, 14)   2048        convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 512, 14, 14)   0           batchnormalization_14[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_2 (UpSampling2D)    (None, 512, 28, 28)   0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 768, 28, 28)   0           upsampling2d_2[0][0]             \n",
      "                                                                   activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 256, 28, 28)   1769728     merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorm (None, 256, 28, 28)   1024        convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 256, 28, 28)   0           batchnormalization_15[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 256, 28, 28)   590080      activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorm (None, 256, 28, 28)   1024        convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 256, 28, 28)   0           batchnormalization_16[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_3 (UpSampling2D)    (None, 256, 56, 56)   0           activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 384, 56, 56)   0           upsampling2d_3[0][0]             \n",
      "                                                                   activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 128, 56, 56)   442496      merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorm (None, 128, 56, 56)   512         convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 128, 56, 56)   0           batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 128, 56, 56)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorm (None, 128, 56, 56)   512         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 128, 56, 56)   0           batchnormalization_18[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_4 (UpSampling2D)    (None, 128, 112, 112) 0           activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 192, 112, 112) 0           upsampling2d_4[0][0]             \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 64, 112, 112)  110656      merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorm (None, 64, 112, 112)  256         convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 64, 112, 112)  0           batchnormalization_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 64, 112, 112)  36928       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorm (None, 64, 112, 112)  256         convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 64, 112, 112)  0           batchnormalization_20[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_5 (UpSampling2D)    (None, 64, 224, 224)  0           activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 96, 224, 224)  0           upsampling2d_5[0][0]             \n",
      "                                                                   activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 32, 224, 224)  27680       merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_21 (BatchNorm (None, 32, 224, 224)  128         convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 32, 224, 224)  0           batchnormalization_21[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 32, 224, 224)  9248        activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 32, 224, 224)  128         convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 32, 224, 224)  0           batchnormalization_22[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 2, 224, 224)   66          activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 2, 224, 224)   0           convolution2d_23[0][0]           \n",
      "====================================================================================================\n",
      "Total params: 31,466,786\n",
      "Trainable params: 31,454,754\n",
      "Non-trainable params: 12,032\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2017-03-28 22:48:13.662957 - Start training ...\n",
      "('Training parameters: ', 4, 50, 1024, 256)\n",
      "Load existing file: /Users/vfomin/Documents/ML/Kaggle/Intel_MobileODT/input/generated/os_cervix_stats.npz\n",
      "No need to recompute statistics\n",
      "Epoch 1/50\n",
      " 272/1024 [======>.......................] - ETA: 547s - loss: 0.6010 - jaccard_index: 0.3990 - recall: 0.8244 - precision: 0.6302"
     ]
    }
   ],
   "source": [
    "nb_epochs = 50\n",
    "batch_size = 4   \n",
    "\n",
    "print(\"\\n {} - Start training ...\".format(datetime.datetime.now()))\n",
    "train(unet, train_id_type_list, val_id_type_list, nb_epochs=nb_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"\\n {} - Start validation ...\".format(datetime.datetime.now()))\n",
    "#validate(unet, val_id_type_list, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_id_type_list = get_test_id_type_list2(annotations)\n",
    "#print(\"\\n {} - Start predictions and write detections\".format(datetime.datetime.now()))\n",
    "#predict(unet, info='unet_no_additional', batch_size=batch_size)\n",
    "#print(\"\\n {} - Scripted finished\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submit job with `qsub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from qsub_utils import submit_job\n",
    "from qsub_utils import setup_configuration\n",
    "from qsub_utils import PBS_CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_configuration(nodes='1:knl7210:ram96gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a8d637cf92bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m process, job_info = submit_job(unet_cervix_os_detection_with_keras_cmd, \n\u001b[1;32m      9\u001b[0m                                \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unet_cervix_os_detection'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                cwd=RESOURCES_PATH)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vfomin/Documents/ML/Kaggle/Intel_MobileODT/notebooks/../common/qsub_utils.py\u001b[0m in \u001b[0;36msubmit_job\u001b[0;34m(cmd, name, cwd, env)\u001b[0m\n\u001b[1;32m     88\u001b[0m     process = subprocess.Popen(program,\n\u001b[1;32m     89\u001b[0m                                \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                                stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\d+.\\w+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mp2cread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2cwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 errread, errwrite)\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# Preserve original exception in case os.close raises.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mchild_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "unet_cervix_os_detection_with_keras_cmd = [\n",
    "    \"python\",\n",
    "    os.path.abspath(os.path.join(\"..\", \"scripts\", \"unet_cervix_os_detection_with_keras.py\"))\n",
    "]\n",
    "\n",
    "process, job_info = submit_job(unet_cervix_os_detection_with_keras_cmd, \n",
    "                               name='unet_cervix_os_detection', \n",
    "                               cwd=RESOURCES_PATH)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        out = process.stdout.readline()    \n",
    "        if len(out) > 0:        \n",
    "            print out\n",
    "\n",
    "        if process.poll() is not None and len(out) == 0:\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    !qdel {job_info['id']}\n",
    "    time.sleep(1.0)\n",
    "    !qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device 0 failed:\n",
      "initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vfomin/Documents/ML/Kaggle/Intel_MobileODT/scripts/unet_cervix_os_detection_with_keras.py\", line 8, in <module>\n",
      "    from keras.callbacks import ModelCheckpoint\n",
      "  File \"/usr/local/lib/python2.7/site-packages/keras/__init__.py\", line 2, in <module>\n",
      "    from . import backend\n",
      "  File \"/usr/local/lib/python2.7/site-packages/keras/backend/__init__.py\", line 64, in <module>\n",
      "    from .theano_backend import *\n",
      "  File \"/usr/local/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1, in <module>\n",
      "    import theano\n",
      "  File \"/usr/local/lib/python2.7/site-packages/theano/__init__.py\", line 108, in <module>\n",
      "    import theano.sandbox.cuda\n",
      "  File \"/usr/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py\", line 728, in <module>\n",
      "    use(device=config.device, force=config.force_device, test_driver=False)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py\", line 571, in use\n",
      "    gpu_init(device, config.lib.cnmem)\n",
      "RuntimeError: ('initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1\\n', 'You asked to force this device and it failed. No fallback to the cpu or other gpu device.')\n"
     ]
    }
   ],
   "source": [
    "#!{\" \".join(unet_cervix_os_detection_with_keras_cmd)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
