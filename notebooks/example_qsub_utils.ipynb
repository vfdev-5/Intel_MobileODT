{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very basic `qsub`, `qstat`, `qdel` Python wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# qsub_utils\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "import logging\n",
    "\n",
    "PBS_CONFIGURATION = {}\n",
    "logger = logging.getLogger('qsub_utils')\n",
    "\n",
    "\n",
    "def setup_configuration(nodes=''):\n",
    "    \"\"\"\n",
    "    Method to setup PBS configuration\n",
    "    :param nodes: specify nodes with list of features. `-l nodes={nodes}`\n",
    "    \"\"\"\n",
    "    global PBS_CONFIGURATION   \n",
    "    if len(nodes) > 0:\n",
    "        PBS_CONFIGURATION['nodes'] = nodes\n",
    "        \n",
    "\n",
    "def get_configuration_str(conf_dict):\n",
    "    \"\"\"\n",
    "    Method to convert configuration dictionary to string\n",
    "    \"\"\"\n",
    "    conf_str = \"#PBS\"    \n",
    "    if 'nodes' in conf_dict:\n",
    "        conf_str += \" -l nodes=%s\" % conf_dict['nodes']\n",
    "    if 'name' in conf_dict:\n",
    "        conf_str += \" -N %s\" % conf_dict['name']\n",
    "    if 'cwd' in conf_dict:         \n",
    "        conf_str += \" -d %s\" % conf_dict['cwd'] \n",
    "    if 'stdout' in conf_dict:\n",
    "        conf_str += \" -o %s\" % conf_dict['stdout']\n",
    "    if 'stderr' in conf_dict:        \n",
    "        conf_str += \" -e %s\" % conf_dict['stderr']           \n",
    "    return conf_str\n",
    "\n",
    "    \n",
    "def write_launch_file(cmd_str, conf_dict, env=''):\n",
    "    \"\"\"\n",
    "    Method to write a PBS launch file for qsub\n",
    "\n",
    "    :param cmd_str: command string, e.g \"python -c \\'import sys; sys.print\\'\"\n",
    "    :param name: name of the job\n",
    "    :param cwd: current working directory\n",
    "    :param env: environmanet string, e.g. \"export PATH=$PATH:/path/to/bin\"\n",
    "    \"\"\"\n",
    "    with open(conf_dict['launch'], 'w') as w:        \n",
    "        w.write(get_configuration_str(conf_dict) + '\\n\\n')\n",
    "        if len(env) > 0:\n",
    "            w.write(env + '\\n')\n",
    "        w.write(cmd_str)\n",
    "\n",
    "\n",
    "def submit_job(cmd, name, cwd='', env=''):\n",
    "    \"\"\"\n",
    "    Method to submit a job writing a launch file and using qsub\n",
    "    `qsub job_{name}.launch`\n",
    "\n",
    "    :param cmd: list of commands, e.g. ['python', '-c', '\\\"import sys; print sys.path\\\"']\n",
    "    :param name: name of the job\n",
    "    :param cwd: current working directory\n",
    "    :param env: environmanet string, e.g. \"export PATH=$PATH:/path/to/bin\"\n",
    "    \"\"\"\n",
    "    assert len(name) > 0, \"Job name can not be empty\"\n",
    "    assert len(cmd) > 0, \"Job command can not be empty\"     \n",
    "    \n",
    "    if ' ' in name:\n",
    "        name = name.replace(' ', '_')    \n",
    "\n",
    "    filename = os.path.join(cwd, '%s.launch' % name)\n",
    "        \n",
    "    job_conf = dict()\n",
    "    job_conf['nodes'] = PBS_CONFIGURATION['nodes']\n",
    "    job_conf['name'] = name\n",
    "    if len(cwd) > 0: job_conf['cwd'] = cwd\n",
    "    job_conf['launch'] = filename\n",
    "    job_conf['stdout'] = os.path.join(cwd, \"log.out\")\n",
    "    job_conf['stderr'] = os.path.join(cwd, \"log.err\")\n",
    "        \n",
    "    write_launch_file(' '.join(cmd), job_conf, env)\n",
    "    program = ['qsub', filename]\n",
    "    process = subprocess.Popen(program,\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE,\n",
    "                               close_fds=False if platform.system() == 'Windows' else True)\n",
    "    process.wait()\n",
    "    job_id = process.stdout.read()\n",
    "    assert job_id is not None and len(job_id) > 0, \"Failed to fetch job id from qsub\"\n",
    "\n",
    "    job_conf['id'] = job_id.replace('\\n', '')\n",
    "    return job_conf\n",
    "\n",
    "\n",
    "def delete_job(job_id):\n",
    "    if not job_is_running(job_id):\n",
    "        logger.warn(\"Job '%s' is not running. Can not delete job\" % job_id)\n",
    "        return False\n",
    "    _id = _get_id(job_id)\n",
    "    program = ['qdel', _id]\n",
    "    process = subprocess.Popen(program,\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE,\n",
    "                               close_fds=False if platform.system() == 'Windows' else True)\n",
    "    returncode = process.wait()\n",
    "    return returncode == 0\n",
    "\n",
    "\n",
    "def _get_id(job_id):\n",
    "    _id = job_id.split('.')[0]\n",
    "    return _id\n",
    "\n",
    "\n",
    "def get_stats(job_id):\n",
    "    _id = _get_id(job_id)\n",
    "    program = ['qstat', '-f', _id]\n",
    "    process = subprocess.Popen(program,\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE,\n",
    "                               close_fds=False if platform.system() == 'Windows' else True)\n",
    "    process.wait()\n",
    "    out = process.stdout.read()\n",
    "    out = out.split('\\n')\n",
    "    stats = {}\n",
    "    if len(out) > 0:\n",
    "        for line in out:\n",
    "            kv = line.split(' = ')\n",
    "            if len(kv) > 1:\n",
    "                stats[kv[0].strip()] = kv[1].strip()\n",
    "    return stats\n",
    "\n",
    "\n",
    "def job_is_running(job_id):\n",
    "    stats = get_stats(job_id)\n",
    "    if len(stats) > 0:\n",
    "        \"\"\"\n",
    "        the job states\n",
    "            E -    Job is exiting after having run.\n",
    "            H -    Job is held.\n",
    "            Q -    job is queued, eligable to run or routed.\n",
    "            R -    job is running.\n",
    "            T -    job is being moved to new location.\n",
    "            W -    job is waiting for its execution time (-a option) to be reached.\n",
    "            S -    (Unicos only) job is suspend.\n",
    "        \"\"\"\n",
    "        if stats['job_state'] in ['R', 'Q', 'H', 'T', 'W']:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_stdout(job_info):\n",
    "    filename = job_info['stdout']\n",
    "    if not os.path.exists(filename):\n",
    "        logger.warn(\"Stdout filename %s' is not found\" % filename)\n",
    "        return None\n",
    "    out = []\n",
    "    with open(filename, 'r') as r:\n",
    "        while True:\n",
    "            line = r.readline()\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "            out.append(line)\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_stderr(job_info):\n",
    "    filename = job_info['stderr']\n",
    "    if not os.path.exists(filename):\n",
    "        logger.warn(\"Stdout filename %s' is not found\" % filename)\n",
    "        return None\n",
    "    out = []\n",
    "    with open(filename, 'r') as r:\n",
    "        while True:\n",
    "            line = r.readline()\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "        out.append(line)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_configuration(nodes='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': '1'}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PBS_CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before while\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "caffe_help_cmd = [\n",
    "    \"caffe\",\n",
    "    \"--help\", \n",
    "]\n",
    "job_info = submit_job(caffe_help_cmd, 'caffe_help', env='export PATH=$PATH:/opt/caffe-master/build/tools/')\n",
    "\n",
    "print('Before while')\n",
    "while job_is_running(job_info['id']):        \n",
    "    print('-')\n",
    "    time.sleep(0.5)\n",
    "#     print delete_job(job_info['id'])\n",
    "    \n",
    "stats = get_stats(job_info['id'])\n",
    "print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'qsub: waiting for job 3958.c001 to startqsub: job 3958.c001 ready\\r  ########################################################################\\r  # Colfax Cluster - https://colfaxresearch.com/\\r  #      Date:           Tue Mar 21 10:10:12 PDT 2017\\r  #    Job ID:           3958.c001\\r  #      User:           u2459\\r  # Resources:           neednodes=1,nodes=1,walltime=24:00:00\\r  ########################################################################\\r  \\r-bash: caffe_help.launch: command not found\\rqsub: job 3958.c001 completed',\n",
       " 'launch': 'caffe_help.launch',\n",
       " 'name': 'caffe_help',\n",
       " 'nodes': '1',\n",
       " 'stderr': 'log.err',\n",
       " 'stdout': 'log.out'}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import time \n",
    "\n",
    "# python_inf_cmd = [\n",
    "#     \"python\",\n",
    "#     \"-c \\\"print(\\'YOU SHOULD SEE THIS\\')\\\"\", \n",
    "# ]\n",
    "\n",
    "# job_info = submit_job(python_inf_cmd, 'python_sys', env='export PATH=$PATH:/opt/caffe-master/build/tools/')\n",
    "\n",
    "# print('Before while')\n",
    "# while job_is_running(job_info['id']):        \n",
    "#     print('-')\n",
    "#     time.sleep(0.5)\n",
    "# #     print delete_job(job_info['id'])\n",
    "    \n",
    "# stats = get_stats(job_info['id'])\n",
    "# print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3916.c001',\n",
       " 'launch': 'caffe_help.launch',\n",
       " 'name': 'caffe_help',\n",
       " 'nodes': '1',\n",
       " 'stderr': 'log.err',\n",
       " 'stdout': 'log.out'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "#PBS -l nodes=1 -N caffe_help -o log.out -e log.err\r\n",
      "\r\n",
      "caffe --help\r\n"
     ]
    }
   ],
   "source": [
    "!cat {job_info['launch']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: caffe_help.launch: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!{job_info['launch']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caffe_help.launch'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info['launch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qsub: waiting for job 3957.c001 to start\n",
      "qsub: job 3957.c001 ready\n",
      "\n",
      "\n",
      "  ########################################################################\n",
      "  # Colfax Cluster - https://colfaxresearch.com/\n",
      "  #      Date:           Tue Mar 21 10:01:15 PDT 2017\n",
      "  #    Job ID:           3957.c001\n",
      "  #      User:           u2459\n",
      "  # Resources:           neednodes=1,nodes=1,walltime=24:00:00\n",
      "  ########################################################################\n",
      "  \n",
      "caffe: command line brew\n",
      "usage: caffe <command> <args>\n",
      "\n",
      "commands:\n",
      "  train           train or finetune a model\n",
      "  test            score a model\n",
      "  data_server     run data server - remote data source\n",
      "  device_query    show GPU diagnostic information\n",
      "  time            benchmark model execution time\n",
      "  collect         collects layer data on specified device\n",
      "  compare         collects layer data using inputs from other device\n",
      "\n",
      "  Flags from /builddir/build/BUILD/gflags-2.1.1/src/gflags.cc:\n",
      "    -flagfile (load flags from file) type: string default: \"\"\n",
      "    -fromenv (set flags from the environment [use 'export FLAGS_flag1=value'])\n",
      "      type: string default: \"\"\n",
      "    -tryfromenv (set flags from the environment if present) type: string\n",
      "      default: \"\"\n",
      "    -undefok (comma-separated list of flag names that it is okay to specify on\n",
      "      the command line even if the program does not define a flag with that\n",
      "      name.  IMPORTANT: flags in this list that have arguments MUST use the\n",
      "      flag=value format) type: string default: \"\"\n",
      "\n",
      "  Flags from /builddir/build/BUILD/gflags-2.1.1/src/gflags_completions.cc:\n",
      "    -tab_completion_columns (Number of columns to use in output for tab\n",
      "      completion) type: int32 default: 80\n",
      "    -tab_completion_word (If non-empty, HandleCommandLineCompletions() will\n",
      "      hijack the process and attempt to do bash-style command line flag\n",
      "      completion on this value.) type: string default: \"\"\n",
      "\n",
      "  Flags from /builddir/build/BUILD/gflags-2.1.1/src/gflags_reporting.cc:\n",
      "    -help (show help on all flags [tip: all flags can have two dashes])\n",
      "      type: bool default: false currently: true\n",
      "    -helpfull (show help on all flags -- same as -help) type: bool\n",
      "      default: false\n",
      "    -helpmatch (show help on modules whose name contains the specified substr)\n",
      "      type: string default: \"\"\n",
      "    -helpon (show help on the modules named by this flag value) type: string\n",
      "      default: \"\"\n",
      "    -helppackage (show help on all modules in the main package) type: bool\n",
      "      default: false\n",
      "    -helpshort (show help on only the main module for this program) type: bool\n",
      "      default: false\n",
      "    -helpxml (produce an xml version of help) type: bool default: false\n",
      "    -version (show version and build info and exit) type: bool default: false\n",
      "\n",
      "\n",
      "\n",
      "  Flags from src/logging.cc:\n",
      "    -alsologtoemail (log messages go to these email addresses in addition to\n",
      "      logfiles) type: string default: \"\"\n",
      "    -alsologtostderr (log messages go to stderr in addition to logfiles)\n",
      "      type: bool default: false currently: true\n",
      "    -colorlogtostderr (color messages logged to stderr (if supported by\n",
      "      terminal)) type: bool default: false\n",
      "    -drop_log_memory (Drop in-memory buffers of log contents. Logs can grow\n",
      "      very quickly and they are rarely read before they need to be evicted from\n",
      "      memory. Instead, drop them from memory as soon as they are flushed to\n",
      "      disk.) type: bool default: true\n",
      "    -log_backtrace_at (Emit a backtrace when logging at file:linenum.)\n",
      "      type: string default: \"\"\n",
      "    -log_dir (If specified, logfiles are written into this directory instead of\n",
      "      the default logging directory.) type: string default: \"\"\n",
      "    -log_link (Put additional links to the log files in this directory)\n",
      "      type: string default: \"\"\n",
      "    -log_prefix (Prepend the log prefix to the start of each log line)\n",
      "      type: bool default: true\n",
      "    -logbuflevel (Buffer log messages logged at this level or lower (-1 means\n",
      "      don't buffer; 0 means buffer INFO only; ...)) type: int32 default: 0\n",
      "    -logbufsecs (Buffer log messages for at most this many seconds) type: int32\n",
      "      default: 30\n",
      "    -logemaillevel (Email log messages logged at this level or higher (0 means\n",
      "      email all; 3 means email FATAL only; ...)) type: int32 default: 999\n",
      "    -logmailer (Mailer used to send logging email) type: string\n",
      "      default: \"/bin/mail\"\n",
      "    -logtostderr (log messages go to stderr instead of logfiles) type: bool\n",
      "      default: false\n",
      "    -max_log_size (approx. maximum log file size (in MB). A value of 0 will be\n",
      "      silently overridden to 1.) type: int32 default: 1800\n",
      "    -minloglevel (Messages logged at a lower level than this don't actually get\n",
      "      logged anywhere) type: int32 default: 0\n",
      "    -stderrthreshold (log messages at or above this level are copied to stderr\n",
      "      in addition to logfiles.  This flag obsoletes --alsologtostderr.)\n",
      "      type: int32 default: 2\n",
      "    -stop_logging_if_full_disk (Stop attempting to log to disk if the disk is\n",
      "      full.) type: bool default: false\n",
      "\n",
      "  Flags from src/utilities.cc:\n",
      "    -symbolize_stacktrace (Symbolize the stack trace in the tombstone)\n",
      "      type: bool default: true\n",
      "\n",
      "  Flags from src/vlog_is_on.cc:\n",
      "    -v (Show all VLOG(m) messages for m <= this. Overridable by --vmodule.)\n",
      "      type: int32 default: 0\n",
      "    -vmodule (per-module verbose level. Argument is a comma-separated list of\n",
      "      <module name>=<log level>. <module name> is a glob pattern, matched\n",
      "      against the filename base (that is, name ignoring .cc/.h./-inl.h). <log\n",
      "      level> overrides any value given by --v.) type: string default: \"\"\n",
      "\n",
      "\n",
      "\n",
      "  Flags from tools/caffe.cpp:\n",
      "    -comm_threads (Optional; multinode mode, The number of threads used by\n",
      "      communication code.) type: int32 default: 1\n",
      "    -engine (Optional; Engine sequence in format:\n",
      "      engine:subengine_1,subengine_2,...) type: string default: \"\"\n",
      "    -forward_only (Optional; Execute only forward pass) type: bool\n",
      "      default: false\n",
      "    -gpu (Optional; run in GPU mode on given device IDs separated by ','.Use\n",
      "      '-gpu all' to run on all available GPUs. The effective training batch\n",
      "      size is multiplied by the number of devices.) type: string default: \"\"\n",
      "    -iterations (The number of iterations to run.) type: int32 default: 50\n",
      "    -level (Optional; network level.) type: int32 default: 0\n",
      "    -listen_address (Optional; multinode mode, bind address for data server)\n",
      "      type: string default: \"\"\n",
      "    -model (The model definition protocol buffer text file.) type: string\n",
      "      default: \"\"\n",
      "    -param_server (Optional; triggers multinode mode, usage:\n",
      "      --param_server=mpi) type: string default: \"\"\n",
      "    -phase (Optional; network phase (TRAIN or TEST). Only used for 'time'.)\n",
      "      type: string default: \"\"\n",
      "    -sighup_effect (Optional; action to take when a SIGHUP signal is received:\n",
      "      snapshot, stop or none.) type: string default: \"snapshot\"\n",
      "    -sigint_effect (Optional; action to take when a SIGINT signal is received:\n",
      "      snapshot, stop or none.) type: string default: \"stop\"\n",
      "    -snapshot (Optional; the snapshot solver state to resume training.)\n",
      "      type: string default: \"\"\n",
      "    -solver (The solver definition protocol buffer text file.) type: string\n",
      "      default: \"\"\n",
      "    -stage (Optional; network stages (not to be confused with phase), separated\n",
      "      by ','.) type: string default: \"\"\n",
      "    -weights (Optional; the pretrained weights to initialize finetuning,\n",
      "      separated by ','. Cannot be set simultaneously with snapshot.)\n",
      "      type: string default: \"\"\n",
      "\n",
      "qsub: job 3957.c001 completed\n"
     ]
    }
   ],
   "source": [
    "!export PATH=\"$PATH:/opt/caffe-master/build/tools/\" && qsub -V -I -x ~/Intel_MobileODT/notebooks/caffe_help.launch\n",
    "#!echo /opt/caffe-master/build/tools/caffe --help | qsub -l nodes=1 -N python_sys -o log.out -e log.err "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 15720\r\n",
      "drwxrwxr-x.  4 u2459 u2459     4096 Mar 21  2017 .\r\n",
      "drwxrwxr-x. 10 u2459 u2459     4096 Mar 20 03:28 ..\r\n",
      "-rw-rw-r--.  1 u2459 u2459      114 Mar 21  2017 caffe_help.launch\r\n",
      "-rw-rw-r--.  1 u2459 u2459      821 Mar 20 18:55 cervix_detector.ipynb\r\n",
      "-rw-rw-r--.  1 u2459 u2459     9947 Mar 20 18:55 colfax_intel_caffe_tryouts.ipynb\r\n",
      "-rw-rw-r--.  1 u2459 u2459 15299022 Mar 20 03:28 data_exploration.ipynb\r\n",
      "-rw-rw-r--.  1 u2459 u2459   174919 Mar 20 03:28 dev_unet.ipynb\r\n",
      "-rw-rw-r--.  1 u2459 u2459    36857 Mar 20 03:28 digits__data_preparation.ipynb\r\n",
      "-rw-rw-r--.  1 u2459 u2459    58493 Mar 21  2017 example_qsub_utils.ipynb\r\n",
      "drwxr-xr-x.  2 u2459 u2459     4096 Mar 20 18:56 .ipynb_checkpoints\r\n",
      "-rw-rw-r--.  1 u2459 u2459      154 Mar 21  2017 job_caffe_help.launch\r\n",
      "-rw-rw-r--.  1 u2459 u2459      155 Mar 21 04:20 job_python_inf.launch\r\n",
      "-rw-------.  1 u2459 u2459        0 Mar 21 08:26 log.err\r\n",
      "-rw-------.  1 u2459 u2459      634 Mar 21 08:26 log.out\r\n",
      "-rw-rw-r--.  1 u2459 u2459      142 Mar 21  2017 python_sys.launch\r\n",
      "-rw-rw-r--.  1 u2459 u2459    67144 Mar 20 18:55 resnet_with_keras.ipynb\r\n",
      "-rw-rw-r--.  1 u2459 u2459   369605 Mar 20 03:28 test_data_iterator.ipynb\r\n",
      "-rw-rw-r--.  1 u2459 u2459    26096 Mar 20 03:28 unet_with_keras.ipynb\r\n",
      "drwxrwxr-x.  2 u2459 u2459       53 Mar 20 03:28 weights\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '  ########################################################################\\n', '  # Colfax Cluster - https://colfaxresearch.com/\\n', '  #      Date:           Tue Mar 21 08:26:36 PDT 2017\\n', '  #    Job ID:           3917.c001\\n', '  #      User:           u2459\\n', '  # Resources:           neednodes=1,nodes=1,walltime=24:00:00\\n', '  ########################################################################\\n', '  \\n', '\\n', '  ########################################################################\\n', '  # Colfax Cluster\\n', '  # End of output for job 3917.c001\\n', '  # Date: Tue Mar 21 08:26:37 PDT 2017\\n', '  ########################################################################\\n', '  \\n']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "out = get_stdout(job_info)\n",
    "err = get_stderr(job_info)\n",
    "\n",
    "print out\n",
    "print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  ########################################################################\r\n",
      "  # Colfax Cluster - https://colfaxresearch.com/\r\n",
      "  #      Date:           Tue Mar 21 08:26:36 PDT 2017\r\n",
      "  #    Job ID:           3917.c001\r\n",
      "  #      User:           u2459\r\n",
      "  # Resources:           neednodes=1,nodes=1,walltime=24:00:00\r\n",
      "  ########################################################################\r\n",
      "  \r\n",
      "\r\n",
      "  ########################################################################\r\n",
      "  # Colfax Cluster\r\n",
      "  # End of output for job 3917.c001\r\n",
      "  # Date: Tue Mar 21 08:26:37 PDT 2017\r\n",
      "  ########################################################################\r\n",
      "  \r\n"
     ]
    }
   ],
   "source": [
    "!cat log.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /var/log/messages: Permission denied\r\n"
     ]
    }
   ],
   "source": [
    "!cat /var/log/messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cervix_detector.ipynb\t\t  log.err\r\n",
      "colfax_intel_caffe_tryouts.ipynb  log.out\r\n",
      "data_exploration.ipynb\t\t  python_sys.launch\r\n",
      "dev_unet.ipynb\t\t\t  resnet_with_keras.ipynb\r\n",
      "digits__data_preparation.ipynb\t  test_data_iterator.ipynb\r\n",
      "example_qsub_utils.ipynb\t  unet_with_keras.ipynb\r\n",
      "job_caffe_help.launch\t\t  weights\r\n",
      "job_python_inf.launch\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cwd': '',\n",
       " 'id': '3855.c001',\n",
       " 'launch_filename': 'job_python_inf.launch',\n",
       " 'name': 'python_inf',\n",
       " 'stderr_filename': '/home/u2459/python_inf.e3855',\n",
       " 'stdout_filename': '/home/u2459/python_inf.o3855'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print delete_job(job_info['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PBS -l nodes=1:knl7210:ram96gb -o /home/u2459 -e /home/u2459 -N python_inf\r\n",
      "export PATH=$PATH:/opt/caffe-master/build/tools/\r\n",
      "python -c \"import time;time.sleep(1000000000)\""
     ]
    }
   ],
   "source": [
    "!cat {filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!rm ~/python_inf.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_opencv\t     Intel_MobileODT  start_digits.sh\ttest_launch\r\n",
      "DIGITS\t\t     keras_source     start_digits.sh~\ttest.py\r\n",
      "digits_dependencies  opencv\t      STDIN.e3535\ttmp\r\n",
      "env.local\t     opencv_source    STDIN.o3535\r\n"
     ]
    }
   ],
   "source": [
    "!ls ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qstat: Unknown Job Id Error 3840.c001\r\n"
     ]
    }
   ],
   "source": [
    "!qstat -f {job_id.split(\".\")[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out split ['']\n",
      "\n",
      "STATS: {}\n",
      "\n",
      "ERR:  qstat: Unknown Job Id Error 3835.c001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_stats(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qstat: Unknown Job Id Error 38454.c001\r\n"
     ]
    }
   ],
   "source": [
    "!qstat -f 38454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_opencv\t     keras_source      STDIN.e3535  Train_Caffe_Model.e3859\r\n",
      "DIGITS\t\t     opencv\t       STDIN.o3535  Train_Caffe_Model.o3859\r\n",
      "digits_dependencies  opencv_source     test_launch\r\n",
      "env.local\t     start_digits.sh   test.py\r\n",
      "Intel_MobileODT      start_digits.sh~  tmp\r\n"
     ]
    }
   ],
   "source": [
    "!ls ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 34:ln=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:mh=00:pi=40: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 33:so=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:do=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:bd=40: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 33: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 01:cd=40: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 33: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 01:or=40: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 01:mi=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 05: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 37: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 41:su=37: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 41:sg=30: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 43:ca=30: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 41:tw=30: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 42:ow=34: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 42:st=37: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 44:ex=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 32:*.tar=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.tgz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.arc=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.arj=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.taz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.lha=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.lz4=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.lzh=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.lzma=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.tlz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.txz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.tzo=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.t7z=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.zip=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.z=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.Z=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.dz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.gz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.lrz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.lz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.lzo=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.xz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.bz2=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.bz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.tbz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.tbz2=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.tz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.deb=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.rpm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.jar=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.war=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.ear=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.sar=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.rar=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.alz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.ace=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.zoo=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.cpio=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.7z=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.rz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.cab=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 31:*.jpg=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.jpeg=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.gif=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.bmp=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.pbm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.pgm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.ppm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.tga=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.xbm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.xpm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.tif=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.tiff=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.png=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.svg=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.svgz=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.mng=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.pcx=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.mov=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.mpg=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.mpeg=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.m2v=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.mkv=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.webm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.ogm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.mp4=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.m4v=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.mp4v=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.vob=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.qt=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.nuv=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.wmv=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.asf=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.rm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.rmvb=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.flc=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.avi=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.fli=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.flv=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.gl=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.dl=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.xcf=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.xwd=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.yuv=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.cgm=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.emf=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.axv=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.anx=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.ogv=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.ogx=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 35:*.aac=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.au=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.flac=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.mid=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.midi=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.mka=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.mp3=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.mpc=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.ogg=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.ra=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.wav=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.axa=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.oga=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.spx=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:*.xspf=01: command not found\r\n",
      "/var/spool/torque/mom_priv/jobs/3859.c001.SC: line 3: 36:: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!cat ~/Train_Caffe_Model.e3859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  ########################################################################\r\n",
      "  # Colfax Cluster - https://colfaxresearch.com/\r\n",
      "  #      Date:           Tue Mar 21 04:17:42 PDT 2017\r\n",
      "  #    Job ID:           3859.c001\r\n",
      "  #      User:           u2459\r\n",
      "  # Resources:           neednodes=1:knl7210:ram96gb,nodes=1:knl7210:ram96gb,walltime=24:00:00\r\n",
      "  ########################################################################\r\n",
      "  \r\n",
      "\r\n",
      "  ########################################################################\r\n",
      "  # Colfax Cluster\r\n",
      "  # End of output for job 3859.c001\r\n",
      "  # Date: Tue Mar 21 04:17:43 PDT 2017\r\n",
      "  ########################################################################\r\n",
      "  \r\n"
     ]
    }
   ],
   "source": [
    "!cat ~/Train_Caffe_Model.o3859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe_output.log\t      original.prototxt  Train_Caffe_Model.e3889\r\n",
      "deploy.prototxt\t\t      solver.prototxt\t Train_Caffe_Model.o3889\r\n",
      "job_Train_Caffe_Model.launch  status.pickle\t train_val.prototxt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/u2459/DIGITS/digits/jobs/20170321-071415-7265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PBS -l nodes=1:knl7210:ram96gb -N Train_Caffe_Model -d /home/u2459/DIGITS/digits/jobs/20170321-071415-7265 -o /home/u2459/DIGITS/digits/jobs/20170321-071415-7265 -e /home/u2459/DIGITS/digits/jobs/20170321-071415-7265\r\n",
      "\r\n",
      "/opt/caffe-master/build/tools/caffe --help"
     ]
    }
   ],
   "source": [
    "!cat /home/u2459/DIGITS/digits/jobs/20170321-071415-7265/job_Train_Caffe_Model.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat /home/u2459/DIGITS/digits/jobs/20170321-071415-7265/Train_Caffe_Model.e3893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3893.c001\r\n"
     ]
    }
   ],
   "source": [
    "!qsub /home/u2459/DIGITS/digits/jobs/20170321-071415-7265/job_Train_Caffe_Model.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890.c001\r\n"
     ]
    }
   ],
   "source": [
    "#!echo /opt/caffe-master/build/tools/caffe --help | qsub -l nodes=1:knl7210:ram96gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!echo caffe_help.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cervix_detector.ipynb\t\t  job_caffe_help.launch\r\n",
      "colfax_intel_caffe_tryouts.ipynb  job_python_inf.launch\r\n",
      "data_exploration.ipynb\t\t  resnet_with_keras.ipynb\r\n",
      "dev_unet.ipynb\t\t\t  test_data_iterator.ipynb\r\n",
      "digits__data_preparation.ipynb\t  unet_with_keras.ipynb\r\n",
      "example_qsub_utils.ipynb\t  weights\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "#!cat STDIN.o3890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PBS -l nodes=1:knl7210:ram96gb -o /home/u2459 -e /home/u2459 -N caffe_help\r\n",
      "export PATH=$PATH:/opt/caffe-master/build/tools/\r\n",
      "caffe --help"
     ]
    }
   ],
   "source": [
    "!cat job_caffe_help.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3897.c001\r\n"
     ]
    }
   ],
   "source": [
    "!qsub job_caffe_help.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  ########################################################################\r\n",
      "  # Colfax Cluster - https://colfaxresearch.com/\r\n",
      "  #      Date:           Tue Mar 21 07:30:16 PDT 2017\r\n",
      "  #    Job ID:           3897.c001\r\n",
      "  #      User:           u2459\r\n",
      "  # Resources:           neednodes=1:knl7210:ram96gb,nodes=1:knl7210:ram96gb,walltime=24:00:00\r\n",
      "  ########################################################################\r\n",
      "  \r\n",
      "caffe: command line brew\r\n",
      "usage: caffe <command> <args>\r\n",
      "\r\n",
      "commands:\r\n",
      "  train           train or finetune a model\r\n",
      "  test            score a model\r\n",
      "  data_server     run data server - remote data source\r\n",
      "  device_query    show GPU diagnostic information\r\n",
      "  time            benchmark model execution time\r\n",
      "  collect         collects layer data on specified device\r\n",
      "  compare         collects layer data using inputs from other device\r\n",
      "\r\n",
      "  Flags from /builddir/build/BUILD/gflags-2.1.1/src/gflags.cc:\r\n",
      "    -flagfile (load flags from file) type: string default: \"\"\r\n",
      "    -fromenv (set flags from the environment [use 'export FLAGS_flag1=value'])\r\n",
      "      type: string default: \"\"\r\n",
      "    -tryfromenv (set flags from the environment if present) type: string\r\n",
      "      default: \"\"\r\n",
      "    -undefok (comma-separated list of flag names that it is okay to specify on\r\n",
      "      the command line even if the program does not define a flag with that\r\n",
      "      name.  IMPORTANT: flags in this list that have arguments MUST use the\r\n",
      "      flag=value format) type: string default: \"\"\r\n",
      "\r\n",
      "  Flags from /builddir/build/BUILD/gflags-2.1.1/src/gflags_completions.cc:\r\n",
      "    -tab_completion_columns (Number of columns to use in output for tab\r\n",
      "      completion) type: int32 default: 80\r\n",
      "    -tab_completion_word (If non-empty, HandleCommandLineCompletions() will\r\n",
      "      hijack the process and attempt to do bash-style command line flag\r\n",
      "      completion on this value.) type: string default: \"\"\r\n",
      "\r\n",
      "  Flags from /builddir/build/BUILD/gflags-2.1.1/src/gflags_reporting.cc:\r\n",
      "    -help (show help on all flags [tip: all flags can have two dashes])\r\n",
      "      type: bool default: false currently: true\r\n",
      "    -helpfull (show help on all flags -- same as -help) type: bool\r\n",
      "      default: false\r\n",
      "    -helpmatch (show help on modules whose name contains the specified substr)\r\n",
      "      type: string default: \"\"\r\n",
      "    -helpon (show help on the modules named by this flag value) type: string\r\n",
      "      default: \"\"\r\n",
      "    -helppackage (show help on all modules in the main package) type: bool\r\n",
      "      default: false\r\n",
      "    -helpshort (show help on only the main module for this program) type: bool\r\n",
      "      default: false\r\n",
      "    -helpxml (produce an xml version of help) type: bool default: false\r\n",
      "    -version (show version and build info and exit) type: bool default: false\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Flags from src/logging.cc:\r\n",
      "    -alsologtoemail (log messages go to these email addresses in addition to\r\n",
      "      logfiles) type: string default: \"\"\r\n",
      "    -alsologtostderr (log messages go to stderr in addition to logfiles)\r\n",
      "      type: bool default: false currently: true\r\n",
      "    -colorlogtostderr (color messages logged to stderr (if supported by\r\n",
      "      terminal)) type: bool default: false\r\n",
      "    -drop_log_memory (Drop in-memory buffers of log contents. Logs can grow\r\n",
      "      very quickly and they are rarely read before they need to be evicted from\r\n",
      "      memory. Instead, drop them from memory as soon as they are flushed to\r\n",
      "      disk.) type: bool default: true\r\n",
      "    -log_backtrace_at (Emit a backtrace when logging at file:linenum.)\r\n",
      "      type: string default: \"\"\r\n",
      "    -log_dir (If specified, logfiles are written into this directory instead of\r\n",
      "      the default logging directory.) type: string default: \"\"\r\n",
      "    -log_link (Put additional links to the log files in this directory)\r\n",
      "      type: string default: \"\"\r\n",
      "    -log_prefix (Prepend the log prefix to the start of each log line)\r\n",
      "      type: bool default: true\r\n",
      "    -logbuflevel (Buffer log messages logged at this level or lower (-1 means\r\n",
      "      don't buffer; 0 means buffer INFO only; ...)) type: int32 default: 0\r\n",
      "    -logbufsecs (Buffer log messages for at most this many seconds) type: int32\r\n",
      "      default: 30\r\n",
      "    -logemaillevel (Email log messages logged at this level or higher (0 means\r\n",
      "      email all; 3 means email FATAL only; ...)) type: int32 default: 999\r\n",
      "    -logmailer (Mailer used to send logging email) type: string\r\n",
      "      default: \"/bin/mail\"\r\n",
      "    -logtostderr (log messages go to stderr instead of logfiles) type: bool\r\n",
      "      default: false\r\n",
      "    -max_log_size (approx. maximum log file size (in MB). A value of 0 will be\r\n",
      "      silently overridden to 1.) type: int32 default: 1800\r\n",
      "    -minloglevel (Messages logged at a lower level than this don't actually get\r\n",
      "      logged anywhere) type: int32 default: 0\r\n",
      "    -stderrthreshold (log messages at or above this level are copied to stderr\r\n",
      "      in addition to logfiles.  This flag obsoletes --alsologtostderr.)\r\n",
      "      type: int32 default: 2\r\n",
      "    -stop_logging_if_full_disk (Stop attempting to log to disk if the disk is\r\n",
      "      full.) type: bool default: false\r\n",
      "\r\n",
      "  Flags from src/utilities.cc:\r\n",
      "    -symbolize_stacktrace (Symbolize the stack trace in the tombstone)\r\n",
      "      type: bool default: true\r\n",
      "\r\n",
      "  Flags from src/vlog_is_on.cc:\r\n",
      "    -v (Show all VLOG(m) messages for m <= this. Overridable by --vmodule.)\r\n",
      "      type: int32 default: 0\r\n",
      "    -vmodule (per-module verbose level. Argument is a comma-separated list of\r\n",
      "      <module name>=<log level>. <module name> is a glob pattern, matched\r\n",
      "      against the filename base (that is, name ignoring .cc/.h./-inl.h). <log\r\n",
      "      level> overrides any value given by --v.) type: string default: \"\"\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Flags from tools/caffe.cpp:\r\n",
      "    -comm_threads (Optional; multinode mode, The number of threads used by\r\n",
      "      communication code.) type: int32 default: 1\r\n",
      "    -engine (Optional; Engine sequence in format:\r\n",
      "      engine:subengine_1,subengine_2,...) type: string default: \"\"\r\n",
      "    -forward_only (Optional; Execute only forward pass) type: bool\r\n",
      "      default: false\r\n",
      "    -gpu (Optional; run in GPU mode on given device IDs separated by ','.Use\r\n",
      "      '-gpu all' to run on all available GPUs. The effective training batch\r\n",
      "      size is multiplied by the number of devices.) type: string default: \"\"\r\n",
      "    -iterations (The number of iterations to run.) type: int32 default: 50\r\n",
      "    -level (Optional; network level.) type: int32 default: 0\r\n",
      "    -listen_address (Optional; multinode mode, bind address for data server)\r\n",
      "      type: string default: \"\"\r\n",
      "    -model (The model definition protocol buffer text file.) type: string\r\n",
      "      default: \"\"\r\n",
      "    -param_server (Optional; triggers multinode mode, usage:\r\n",
      "      --param_server=mpi) type: string default: \"\"\r\n",
      "    -phase (Optional; network phase (TRAIN or TEST). Only used for 'time'.)\r\n",
      "      type: string default: \"\"\r\n",
      "    -sighup_effect (Optional; action to take when a SIGHUP signal is received:\r\n",
      "      snapshot, stop or none.) type: string default: \"snapshot\"\r\n",
      "    -sigint_effect (Optional; action to take when a SIGINT signal is received:\r\n",
      "      snapshot, stop or none.) type: string default: \"stop\"\r\n",
      "    -snapshot (Optional; the snapshot solver state to resume training.)\r\n",
      "      type: string default: \"\"\r\n",
      "    -solver (The solver definition protocol buffer text file.) type: string\r\n",
      "      default: \"\"\r\n",
      "    -stage (Optional; network stages (not to be confused with phase), separated\r\n",
      "      by ','.) type: string default: \"\"\r\n",
      "    -weights (Optional; the pretrained weights to initialize finetuning,\r\n",
      "      separated by ','. Cannot be set simultaneously with snapshot.)\r\n",
      "      type: string default: \"\"\r\n",
      "\r\n",
      "  ########################################################################\r\n",
      "  # Colfax Cluster\r\n",
      "  # End of output for job 3897.c001\r\n",
      "  # Date: Tue Mar 21 07:30:17 PDT 2017\r\n",
      "  ########################################################################\r\n",
      "  \r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/u2459/log.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
