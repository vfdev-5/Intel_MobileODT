{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation fro DIGITS\n",
    "\n",
    "Prepare data as described [here](https://github.com/NVIDIA/DIGITS/blob/master/digits/extensions/data/objectDetection/README.md) to create dataset for object detection task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "import shutil\n",
    "# Numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_annotations(filename):\n",
    "    \"\"\"\n",
    "    :return: ndarray of dicts \n",
    "        {\n",
    "            \"annotations\": [\n",
    "                {\n",
    "                    \"class\": \"os\",\n",
    "                    \"height\": 10.0,\n",
    "                    \"type\": \"rect\",\n",
    "                    \"width\": 20.0,\n",
    "                    \"x\": 52.0,\n",
    "                    \"y\": 48.0\n",
    "                },\n",
    "                {\n",
    "                    \"class\": \"cervix\",\n",
    "                    \"height\": 275.0,\n",
    "                    \"type\": \"rect\",\n",
    "                    \"width\": 300.0,\n",
    "                    \"x\": 10.0,\n",
    "                    \"y\": 5.0\n",
    "                }],\n",
    "            \"class\": \"image\",\n",
    "            \"filename\": \"train/Type_1/590.jpg\"\n",
    "        }\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    with open(filename, 'r') as reader:\n",
    "        str_data = ''.join(reader.readlines())\n",
    "        raw_data = json.loads(str_data)\n",
    "        for item in raw_data:\n",
    "            if len(item['annotations']) > 0:\n",
    "                labels.append(item)\n",
    "    return np.array(labels)\n",
    "   \n",
    "    \n",
    "def write_images_labels(annotations, data_path, output_path, create_sym_links=True):\n",
    "    \"\"\" \n",
    "        LABEL STRUCTURE from DIGITS\\digits\\extensions\\data\\objectDetection\\utils.py\n",
    "    \n",
    "        This class is the data ground-truth\n",
    "\n",
    "        #Values    Name      Description\n",
    "        ----------------------------------------------------------------------------\n",
    "        1    type         Class ID\n",
    "        1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\n",
    "                          truncated refers to the object leaving image boundaries.\n",
    "                          -1 corresponds to a don't care region.\n",
    "        1    occluded     Integer (-1,0,1,2) indicating occlusion state:\n",
    "                          -1 = unkown, 0 = fully visible,\n",
    "                          1 = partly occluded, 2 = largely occluded\n",
    "        1    alpha        Observation angle of object, ranging [-pi..pi]\n",
    "        4    bbox         2D bounding box of object in the image (0-based index):\n",
    "                          contains left, top, right, bottom pixel coordinates\n",
    "        3    dimensions   3D object dimensions: height, width, length (in meters)\n",
    "        3    location     3D object location x,y,z in camera coordinates (in meters)\n",
    "        1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\n",
    "        1    score        Only for results: Float, indicating confidence in\n",
    "                          detection, needed for p/r curves, higher is better.\n",
    "\n",
    "        Here, 'DontCare' labels denote regions in which objects have not been labeled,\n",
    "        for example because they have been too far away from the laser scanner.\n",
    "    \"\"\"\n",
    "    output_images_folder = os.path.join(output_path, \"images\")\n",
    "    os.makedirs(output_images_folder)\n",
    "    \n",
    "    output_labels_folder = os.path.join(output_path, \"labels\")\n",
    "    os.makedirs(output_labels_folder)\n",
    "    \n",
    "    def _clamp(x, dim):\n",
    "        return min(max(x, 0), dim-1)\n",
    "        \n",
    "    for annotation in annotations:\n",
    "        img_filename = annotation['filename']\n",
    "        basename, ext = os.path.splitext(os.path.basename(img_filename))\n",
    "        basename = os.path.split(os.path.dirname(img_filename))[1] + '_' + basename\n",
    "        src_image_filename = os.path.join(data_path, img_filename)\n",
    "        dst_image_filename = os.path.join(output_images_folder, \"%s%s\" % (basename,ext))\n",
    "        dst_label_filename = os.path.join(output_labels_folder, \"%s.txt\" % basename)\n",
    "        \n",
    "        os.symlink(src_image_filename, dst_image_filename)\n",
    "        pil_image = Image.open(img_filename)\n",
    "        image_size = pil_image.size       \n",
    "        \n",
    "        with open(dst_label_filename, 'w') as writer:\n",
    "            for obj in annotation['annotations']:\n",
    "                # format : class_name bbox_left bbox_top bbox_right bbox_bottom\n",
    "                l, t, w, h = int(obj['x']), int(obj['y']), int(obj['width']), int(obj['height'])\n",
    "                r = l+w; b = t+h\n",
    "                l = _clamp(l, image_size[0])\n",
    "                t = _clamp(t, image_size[1])\n",
    "                r = _clamp(r, image_size[0])\n",
    "                b = _clamp(b, image_size[1])\n",
    "                line = \"{type} {truncated} {occluded} {alpha} {l} {t} {r} {b} {h} {w} {le} {x} {y} {z} {ry}\\n\".format(\n",
    "                    type=obj['class'],\n",
    "                    truncated=0.0,\n",
    "                    occluded=-1,\n",
    "                    alpha=0.0,\n",
    "                    l=l, t=t, r=r, b=b,\n",
    "                    h=0.0, w=0.0, le=0.0,\n",
    "                    x=0.0, y=0.0, z=0.0,\n",
    "                    ry = 0.0\n",
    "                )   \n",
    "                writer.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = os.path.join('..')\n",
    "SLOTH_LABELS_PATH = os.path.join('..', 'resources', 'cervix_os.json')\n",
    "TRAIN_TEST_SPLIT=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 208, Train : 145, Val : 63\n"
     ]
    }
   ],
   "source": [
    "annotations = get_annotations(SLOTH_LABELS_PATH)\n",
    "\n",
    "# Create data split\n",
    "num_labels = len(annotations)\n",
    "indices = np.random.permutation(num_labels)\n",
    "split_index = int(num_labels * TRAIN_TEST_SPLIT)\n",
    "train_annotations = annotations[indices[:split_index]]\n",
    "test_annotations = annotations[indices[split_index:]]\n",
    "\n",
    "print \"Total : %s, Train : %s, Val : %s\" % (num_labels, len(train_annotations), len(test_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_filenames = [a['filename'] for a in train_annotations]\n",
    "# test_filenames = [a['filename'] for a in test_annotations]\n",
    "# set(train_filenames) & set(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Following DIGITS conventions : Label files are expected to have the .txt extension. \n",
    "# For example if an image file is named foo.png the corresponding label file should be foo.txt. \n",
    "# And specific for object detection\n",
    "# https://github.com/NVIDIA/DIGITS/tree/master/digits/extensions/data/objectDetection\n",
    "\n",
    "GENERATED_DATA=join(\"..\", \"input\", \"generated\")\n",
    "\n",
    "if os.path.isdir(join(GENERATED_DATA, \"train\")):\n",
    "    shutil.rmtree(join(GENERATED_DATA, \"train\"))\n",
    "if os.path.isdir(join(GENERATED_DATA, \"val\")):\n",
    "    shutil.rmtree(join(GENERATED_DATA, \"val\"))\n",
    "\n",
    "write_images_labels(train_annotations, RAW_DATA_PATH, join(GENERATED_DATA, \"train\"))\n",
    "write_images_labels(test_annotations, RAW_DATA_PATH, join(GENERATED_DATA, \"val\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "!ls {GENERATED_DATA}/train/labels | wc -l\n",
    "!ls {GENERATED_DATA}/val/labels | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type_1_0.txt\t Type_1_376.txt  Type_1_708.txt  Type_1_972.txt\r\n",
      "Type_1_1013.txt  Type_1_379.txt  Type_1_709.txt  Type_1_977.txt\r\n",
      "Type_1_1014.txt  Type_1_383.txt  Type_1_710.txt  Type_1_998.txt\r\n",
      "Type_1_102.txt\t Type_1_387.txt  Type_1_713.txt  Type_2_1197.txt\r\n",
      "Type_1_104.txt\t Type_1_396.txt  Type_1_732.txt  Type_2_1198.txt\r\n",
      "Type_1_109.txt\t Type_1_401.txt  Type_1_739.txt  Type_2_1203.txt\r\n",
      "Type_1_10.txt\t Type_1_41.txt\t Type_1_751.txt  Type_2_1210.txt\r\n",
      "Type_1_129.txt\t Type_1_421.txt  Type_1_759.txt  Type_2_1211.txt\r\n",
      "Type_1_12.txt\t Type_1_425.txt  Type_1_763.txt  Type_2_1218.txt\r\n",
      "Type_1_138.txt\t Type_1_441.txt  Type_1_764.txt  Type_2_1371.txt\r\n",
      "Type_1_144.txt\t Type_1_446.txt  Type_1_779.txt  Type_2_1373.txt\r\n",
      "Type_1_148.txt\t Type_1_454.txt  Type_1_783.txt  Type_2_1376.txt\r\n",
      "Type_1_14.txt\t Type_1_469.txt  Type_1_787.txt  Type_2_1378.txt\r\n",
      "Type_1_160.txt\t Type_1_481.txt  Type_1_7.txt\t Type_2_1379.txt\r\n",
      "Type_1_171.txt\t Type_1_48.txt\t Type_1_805.txt  Type_2_1415.txt\r\n",
      "Type_1_180.txt\t Type_1_536.txt  Type_1_817.txt  Type_2_1416.txt\r\n",
      "Type_1_181.txt\t Type_1_539.txt  Type_1_821.txt  Type_2_1418.txt\r\n",
      "Type_1_191.txt\t Type_1_551.txt  Type_1_842.txt  Type_2_1419.txt\r\n",
      "Type_1_205.txt\t Type_1_55.txt\t Type_1_846.txt  Type_2_1421.txt\r\n",
      "Type_1_218.txt\t Type_1_560.txt  Type_1_855.txt  Type_2_1433.txt\r\n",
      "Type_1_237.txt\t Type_1_562.txt  Type_1_873.txt  Type_2_1435.txt\r\n",
      "Type_1_239.txt\t Type_1_576.txt  Type_1_880.txt  Type_2_1436.txt\r\n",
      "Type_1_248.txt\t Type_1_579.txt  Type_1_887.txt  Type_2_1438.txt\r\n",
      "Type_1_262.txt\t Type_1_57.txt\t Type_1_889.txt  Type_2_1439.txt\r\n",
      "Type_1_267.txt\t Type_1_580.txt  Type_1_890.txt  Type_2_1441.txt\r\n",
      "Type_1_27.txt\t Type_1_605.txt  Type_1_891.txt  Type_2_1443.txt\r\n",
      "Type_1_281.txt\t Type_1_619.txt  Type_1_895.txt  Type_2_1444.txt\r\n",
      "Type_1_294.txt\t Type_1_620.txt  Type_1_906.txt  Type_2_1446.txt\r\n",
      "Type_1_298.txt\t Type_1_623.txt  Type_1_908.txt  Type_2_1450.txt\r\n",
      "Type_1_306.txt\t Type_1_624.txt  Type_1_917.txt  Type_2_1451.txt\r\n",
      "Type_1_308.txt\t Type_1_641.txt  Type_1_918.txt  Type_2_1452.txt\r\n",
      "Type_1_342.txt\t Type_1_649.txt  Type_1_920.txt  Type_2_1454.txt\r\n",
      "Type_1_346.txt\t Type_1_653.txt  Type_1_921.txt  Type_2_1457.txt\r\n",
      "Type_1_349.txt\t Type_1_667.txt  Type_1_928.txt  Type_2_1480.txt\r\n",
      "Type_1_34.txt\t Type_1_668.txt  Type_1_930.txt\r\n",
      "Type_1_356.txt\t Type_1_683.txt  Type_1_965.txt\r\n",
      "Type_1_35.txt\t Type_1_700.txt  Type_1_96.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls {GENERATED_DATA}/train/labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type_1_1019.txt  Type_1_338.txt  Type_1_643.txt  Type_1_901.txt\r\n",
      "Type_1_1023.txt  Type_1_384.txt  Type_1_645.txt  Type_2_1195.txt\r\n",
      "Type_1_139.txt\t Type_1_470.txt  Type_1_663.txt  Type_2_1196.txt\r\n",
      "Type_1_13.txt\t Type_1_471.txt  Type_1_685.txt  Type_2_1201.txt\r\n",
      "Type_1_142.txt\t Type_1_47.txt\t Type_1_725.txt  Type_2_1205.txt\r\n",
      "Type_1_176.txt\t Type_1_484.txt  Type_1_727.txt  Type_2_1209.txt\r\n",
      "Type_1_201.txt\t Type_1_497.txt  Type_1_745.txt  Type_2_1212.txt\r\n",
      "Type_1_208.txt\t Type_1_513.txt  Type_1_765.txt  Type_2_1368.txt\r\n",
      "Type_1_215.txt\t Type_1_516.txt  Type_1_769.txt  Type_2_1369.txt\r\n",
      "Type_1_229.txt\t Type_1_518.txt  Type_1_791.txt  Type_2_1377.txt\r\n",
      "Type_1_245.txt\t Type_1_531.txt  Type_1_802.txt  Type_2_1428.txt\r\n",
      "Type_1_252.txt\t Type_1_550.txt  Type_1_809.txt  Type_2_1432.txt\r\n",
      "Type_1_254.txt\t Type_1_578.txt  Type_1_810.txt  Type_2_1445.txt\r\n",
      "Type_1_311.txt\t Type_1_582.txt  Type_1_81.txt\t Type_2_1449.txt\r\n",
      "Type_1_333.txt\t Type_1_593.txt  Type_1_833.txt  Type_2_1453.txt\r\n",
      "Type_1_334.txt\t Type_1_596.txt  Type_1_836.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls {GENERATED_DATA}/val/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os 0.0 -1 0.0 553 1965 1613 2447 0.0 0.0 0.0 0.0 0.0 0.0 0.0\r\n",
      "cervix 0.0 -1 0.0 327 1220 2143 3197 0.0 0.0 0.0 0.0 0.0 0.0 0.0\r\n"
     ]
    }
   ],
   "source": [
    "!cat {GENERATED_DATA}/val/labels/Type_1_1019.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
