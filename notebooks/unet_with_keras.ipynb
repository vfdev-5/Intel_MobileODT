{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net with FC layer for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Project\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.abspath(os.path.dirname('.')), '..', 'common'))\n",
    "from data_utils import type_1_ids, type_2_ids, type_3_ids, test_ids\n",
    "from training_utils import get_trainval_id_type_lists, get_test_id_type_list, data_iterator\n",
    "from metrics import logloss_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "Training dataset: \n",
      "('- type 1: ', 250)\n",
      "('- type 2: ', 781)\n",
      "('- type 3: ', 450)\n",
      "Test dataset: \n",
      "('- ', 512)\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=========================\")\n",
    "print(\"Training dataset: \")\n",
    "print(\"- type 1: \", len(type_1_ids))\n",
    "print(\"- type 2: \", len(type_2_ids))\n",
    "print(\"- type 3: \", len(type_3_ids))\n",
    "\n",
    "print(\"Test dataset: \")\n",
    "print(\"- \", len(test_ids))\n",
    "print(\"=========================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_id_type_list, val_id_type_list, batch_size=16, nb_epochs=10, image_size=(224, 224)):\n",
    "    samples_per_epoch = 512\n",
    "    nb_val_samples = 128\n",
    "\n",
    "    if not os.path.exists('weights'):\n",
    "        os.mkdir('weights')\n",
    "\n",
    "    weights_filename = os.path.join(\"weights\", \"unet_simple_{epoch:02d}-{val_loss:.4f}.h5\")\n",
    "    model_checkpoint = ModelCheckpoint(weights_filename, monitor='loss', save_best_only=True)\n",
    "\n",
    "    print(\"Training parameters: \", batch_size, nb_epochs, samples_per_epoch, nb_val_samples)\n",
    "    \n",
    "    train_iter = data_iterator(train_id_type_list, batch_size=batch_size, image_size=image_size, \n",
    "verbose=0)\n",
    "    val_iter = data_iterator(val_id_type_list, batch_size=batch_size, image_size=image_size, verbose=0)\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "        train_iter,\n",
    "        samples_per_epoch=samples_per_epoch,\n",
    "        nb_epoch=nb_epochs,\n",
    "        validation_data=val_iter,\n",
    "        nb_val_samples=nb_val_samples,\n",
    "        callbacks=[model_checkpoint],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def validate(model, val_id_type_list, batch_size=16, image_size=(224, 224)):\n",
    "    val_iter = data_iterator(val_id_type_list, batch_size=batch_size, image_size=image_size, test_mode=True)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_counter = 0 \n",
    "    for X, Y_true, _ in val_iter:           \n",
    "        s = Y_true.shape[0]\n",
    "        total_counter += s\n",
    "        Y_pred = model.predict(X)\n",
    "        loss = logloss_mc(Y_true, Y_pred)\n",
    "        total_loss += s * loss\n",
    "        print(\"--\", total_counter, \"batch loss : \", loss)\n",
    "\n",
    "    if total_counter == 0:\n",
    "        total_counter += 1\n",
    "\n",
    "    total_loss *= 1.0 / total_counter   \n",
    "    print(\"Total loss : \", total_loss)\n",
    "    \n",
    "    \n",
    "def predict(model, batch_size=16, image_size=(224, 224), info=''):\n",
    "\n",
    "    test_id_type_list = get_test_id_type_list()\n",
    "    test_iter = data_iterator(test_id_type_list, batch_size=batch_size, image_size=image_size, test_mode=True)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['image_name','Type_1','Type_2','Type_3'])\n",
    "    total_counter = 0\n",
    "    for X, _, image_ids in test_iter:            \n",
    "        Y_pred = model.predict(X)    \n",
    "        s = X.shape[0]\n",
    "        total_counter += s\n",
    "        print(\"--\", total_counter)\n",
    "        for i in range(s):\n",
    "            df.loc[total_counter + i, :] = (image_ids[i] + '.jpg', ) + tuple(Y_pred[i, :])\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    df.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GT 750M (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Keras version: ', '1.2.2')\n"
     ]
    }
   ],
   "source": [
    "from keras import __version__\n",
    "from unet_keras122 import get_unet\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(\"Keras version: \", __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2017-03-19 16:25:04.096696 - Get train/val lists ...\n",
      "Train dataset contains : \n",
      "('-', [175, 546, 315], ' images of corresponding types')\n",
      "Validation dataset contains : \n",
      "('-', [75, 234, 135], ' images of corresponding types')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n {} - Get train/val lists ...\".format(datetime.datetime.now()))\n",
    "train_id_type_list, val_id_type_list = get_trainval_id_type_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2017-03-19 16:25:04.133587 - Get U-Net model ...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 224, 224)  896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 32, 224, 224)  128         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 224, 224)  0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 224, 224)  9248        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 32, 224, 224)  128         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 224, 224)  0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 112, 112)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 112, 112)  18496       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 64, 112, 112)  256         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 64, 112, 112)  0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 112, 112)  36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 64, 112, 112)  256         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 64, 112, 112)  0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 56, 56)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 128, 56, 56)   73856       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 128, 56, 56)   512         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128, 56, 56)   0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 128, 56, 56)   147584      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 128, 56, 56)   512         convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 128, 56, 56)   0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 128, 28, 28)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 28, 28)   295168      maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 256, 28, 28)   1024        convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 256, 28, 28)   0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 256, 28, 28)   590080      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 256, 28, 28)   1024        convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 256, 28, 28)   0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 256, 14, 14)   0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 14, 14)   1180160     maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 512, 14, 14)   2048        convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 512, 14, 14)   0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 14, 14)   2359808     activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 512, 14, 14)   2048        convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 512, 14, 14)   0           batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 1024, 7, 7)    4719616     maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 1024, 7, 7)    4096        convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 1024, 7, 7)    0           batchnormalization_11[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 1024, 7, 7)    9438208     activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 1024, 7, 7)    4096        convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 1024, 7, 7)    0           batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 50176)         0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             150531      flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 19,036,707\n",
      "Trainable params: 19,028,643\n",
      "Non-trainable params: 8,064\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n {} - Get U-Net model ...\".format(datetime.datetime.now()))\n",
    "unet = get_unet()\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2017-03-19 16:25:07.367406 - Start training ...\n",
      "('Training parameters: ', 4, 20, 512, 128)\n",
      "Epoch 1/20\n",
      "188/512 [==========>...................] - ETA: 69s - loss: 6.1562 - acc: 0.3457('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 142s - loss: 5.0277 - acc: 0.3359 - val_loss: 5.2599 - val_acc: 0.2578\n",
      "Epoch 2/20\n",
      "196/512 [==========>...................] - ETA: 55s - loss: 3.6285 - acc: 0.3469('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 144s - loss: 3.4641 - acc: 0.3477 - val_loss: 4.2678 - val_acc: 0.3281\n",
      "Epoch 3/20\n",
      "212/512 [===========>..................] - ETA: 70s - loss: 3.4741 - acc: 0.3868('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 150s - loss: 4.3417 - acc: 0.3359 - val_loss: 3.8547 - val_acc: 0.3047\n",
      "Epoch 4/20\n",
      "287/512 [===============>..............] - ETA: 43s - loss: 4.2299 - acc: 0.3206('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "511/512 [============================>.] - ETA: 0s - loss: 4.1038 - acc: 0.3151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/512 [==============================] - 131s - loss: 4.0784 - acc: 0.3165 - val_loss: 4.3167 - val_acc: 0.2891\n",
      "Epoch 5/20\n",
      "288/512 [===============>..............] - ETA: 41s - loss: 3.7931 - acc: 0.3299('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 126s - loss: 4.0097 - acc: 0.3340 - val_loss: 4.3630 - val_acc: 0.3281\n",
      "Epoch 6/20\n",
      "308/512 [=================>............] - ETA: 37s - loss: 3.6380 - acc: 0.3182('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 126s - loss: 3.4872 - acc: 0.3398 - val_loss: 4.1787 - val_acc: 0.3692\n",
      "Epoch 7/20\n",
      "383/512 [=====================>........] - ETA: 24s - loss: 3.9344 - acc: 0.3864('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "515/512 [==============================] - 124s - loss: 3.8213 - acc: 0.4039 - val_loss: 4.9617 - val_acc: 0.3125\n",
      "Epoch 8/20\n",
      "392/512 [=====================>........] - ETA: 22s - loss: 3.8926 - acc: 0.3418('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 126s - loss: 3.8837 - acc: 0.3496 - val_loss: 4.1861 - val_acc: 0.2812\n",
      "Epoch 9/20\n",
      "404/512 [======================>.......] - ETA: 20s - loss: 4.4032 - acc: 0.3020('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 124s - loss: 4.4967 - acc: 0.2910 - val_loss: 3.2324 - val_acc: 0.3672\n",
      "Epoch 10/20\n",
      "479/512 [===========================>..] - ETA: 6s - loss: 4.2261 - acc: 0.2860('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "515/512 [==============================] - 130s - loss: 4.2268 - acc: 0.2854 - val_loss: 3.7809 - val_acc: 0.3125\n",
      "Epoch 11/20\n",
      "488/512 [===========================>..] - ETA: 4s - loss: 3.9557 - acc: 0.3258('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 131s - loss: 3.9189 - acc: 0.3281 - val_loss: 3.2702 - val_acc: 0.3308\n",
      "Epoch 12/20\n",
      "496/512 [============================>.] - ETA: 3s - loss: 4.0840 - acc: 0.3387('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 125s - loss: 4.1092 - acc: 0.3398 - val_loss: 4.2146 - val_acc: 0.2891\n",
      "Epoch 13/20\n",
      "515/512 [==============================] - 127s - loss: 3.8877 - acc: 0.3262 - val_loss: 3.7178 - val_acc: 0.2969\n",
      "Epoch 14/20\n",
      " 24/512 [>.............................] - ETA: 77s - loss: 3.7167 - acc: 0.3750('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 127s - loss: 3.9345 - acc: 0.3320 - val_loss: 3.2270 - val_acc: 0.3438\n",
      "Epoch 15/20\n",
      " 40/512 [=>............................] - ETA: 79s - loss: 3.7035 - acc: 0.2500('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 126s - loss: 3.8265 - acc: 0.3027 - val_loss: 3.9297 - val_acc: 0.2969\n",
      "Epoch 16/20\n",
      " 52/512 [==>...........................] - ETA: 75s - loss: 4.4012 - acc: 0.2692('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "515/512 [==============================] - 125s - loss: 4.2295 - acc: 0.3126 - val_loss: 3.3071 - val_acc: 0.3615\n",
      "Epoch 17/20\n",
      "140/512 [=======>......................] - ETA: 64s - loss: 3.7153 - acc: 0.2786('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 124s - loss: 3.5670 - acc: 0.2949 - val_loss: 3.3163 - val_acc: 0.3828\n",
      "Epoch 18/20\n",
      "148/512 [=======>......................] - ETA: 66s - loss: 3.6747 - acc: 0.3176('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 126s - loss: 3.7624 - acc: 0.3223 - val_loss: 4.1002 - val_acc: 0.3125\n",
      "Epoch 19/20\n",
      "176/512 [=========>....................] - ETA: 63s - loss: 3.1419 - acc: 0.3580('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "512/512 [==============================] - 138s - loss: 3.4248 - acc: 0.3574 - val_loss: 4.1768 - val_acc: 0.3516\n",
      "Epoch 20/20\n",
      "255/512 [=============>................] - ETA: 49s - loss: 4.3384 - acc: 0.3294('Image is corrupted. Id/Type:', '1339', 'Type_1')\n",
      "515/512 [==============================] - 137s - loss: 4.2659 - acc: 0.3262 - val_loss: 3.6399 - val_acc: 0.3047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148639c90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "batch_size = 4\n",
    "print(\"\\n {} - Start training ...\".format(datetime.datetime.now()))\n",
    "train(unet, train_id_type_list, val_id_type_list, nb_epochs=nb_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n {} - Start validation ...\".format(datetime.datetime.now()))\n",
    "validate(unet, val_id_type_list, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n {} - Start predictions and write submission ...\".format(datetime.datetime.now()))\n",
    "predict(unet, info='unet_no_additional', batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
